# Model Powered by Ipex-LLM

## Verified Models
Verified models can be found from EmbeddedLLM IpexLLM model collections
* EmbeddedLLM IpexLLM Model collections: [link](https://huggingface.co/collections/EmbeddedLLM/ipex-llm-genai-66c85eadb05bb4dedd5e70ca)

| Model | Model Link |
| --- | --- |
| Phi-3-mini-4k-instruct | [link](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) |
| Phi-3-mini-128k-instruct | [link](https://huggingface.co/microsoft/Phi-3-mini-128k-instruct) |
| Phi-3-medium-4k-instruct | [link](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct) |
| Phi-3-medium-128k-instruct | [link](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) |

## Supported Models by Ipex-LLM
Unverified models, but supported by Upstream IpexLLM could be found in the following model collections.

| Model | Model Link |
| --- | --- |
| LLaMA _(such as Vicuna, Guanaco, Koala, Baize, WizardLM, etc.)_ |  |
| LLaMA 2 | [link1](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf), [link2](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) |
| LLaMA 3 | [link](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) |
| ChatGLM |  |
| ChatGLM2 | [link](https://huggingface.co/THUDM/chatglm2-6b) |
| ChatGLM3 | [link](https://huggingface.co/THUDM/chatglm3-6b) |
| GLM-4 | [link](https://huggingface.co/THUDM/glm-4-9b-chat) |
| Mistral | [link](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) |
| Mixtral | [link](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1) |
| Falcon | [link](https://huggingface.co/tiiuae/falcon-7b-instruct) |
| MPT | [link](https://huggingface.co/mosaicml/mpt-7b-chat) |
| Dolly-v1 | [link](https://huggingface.co/databricks/dolly-v1-6b) |
| Dolly-v2 | [link](https://huggingface.co/databricks/dolly-v2-12b) |
| Replit Code | [link](https://huggingface.co/replit/replit-code-v1-3b) |
| RedPajama | [link](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat) |
| Phoenix | [link](https://huggingface.co/FreedomIntelligence/phoenix-inst-chat-7b) |
| StarCoder | [link](https://huggingface.co/bigcode/starcoder) |
| Baichuan | [link](https://huggingface.co/baichuan-inc/Baichuan-13B-Chat) |
| Baichuan2 | [link](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat) |
| InternLM | [link](https://huggingface.co/internlm/internlm-chat-7b) |
| InternLM2 | [link](https://huggingface.co/internlm/internlm2-chat-7b) |
| Qwen | [link](https://huggingface.co/Qwen/Qwen-7B-Chat) |
| Qwen1.5 | [link](https://huggingface.co/Qwen/Qwen1.5-7B-Chat) |
| Qwen2 | [link](https://huggingface.co/Qwen/Qwen2-7B-Instruct) |
| Aquila | [link](https://huggingface.co/BAAI/AquilaChat-7B) |
| Aquila2 | [link](https://huggingface.co/BAAI/AquilaChat2-7B) |
| Phi-1_5 | [link](https://huggingface.co/microsoft/phi-1_5) |
| Flan-t5 | [link](https://huggingface.co/google/flan-t5-xxl) |
| CodeLlama | [link](https://huggingface.co/codellama/CodeLlama-7b-hf) |
| Skywork | [link](https://huggingface.co/Skywork/Skywork-13B-base) |
| InternLM-XComposer | [link](https://huggingface.co/internlm/internlm-xcomposer-vl-7b) |
| CodeShell | [link](https://huggingface.co/WisdomShell/CodeShell-7B) |
| Yi | [link](https://huggingface.co/01-ai/Yi-6B) |
| BlueLM | [link](https://huggingface.co/vivo-ai/BlueLM-7B-Chat) |
| Mamba | [link1](https://huggingface.co/state-spaces/mamba-1.4b), [link2](https://huggingface.co/state-spaces/mamba-2.8b) |
| SOLAR | [link](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0) |
| Phixtral | [link](https://huggingface.co/mlabonne/phixtral-4x2_8) |
| RWKV4 |  |
| RWKV5 |  |
| DeepSeek-MoE | [link](https://huggingface.co/deepseek-ai/deepseek-moe-16b-chat) |
| Ziya-Coding-34B-v1.0 | [link](https://huggingface.co/IDEA-CCNL/Ziya-Coding-34B-v1.0) |
| Phi-2 | [link](https://huggingface.co/microsoft/phi-2) |
| Phi-3 | [link](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) |
| Yuan2 | [link](https://huggingface.co/IEITYuan/Yuan2-2B-hf) |
| Gemma | [link1](https://huggingface.co/google/gemma-2b-it), [link2](https://huggingface.co/google/gemma-7b-it) |
| DeciLM-7B | [link](https://huggingface.co/Deci/DeciLM-7B-instruct) |
| Deepseek | [link](phttps://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct) |
| StableLM | [link](https://huggingface.co/stabilityai/stablelm-zephyr-3b) |
| CodeGemma | [link](https://huggingface.co/google/codegemma-7b-it) |
| Command-R/cohere | [link](https://huggingface.co/CohereForAI/c4ai-command-r-v01) |
| CodeGeeX2 | [link](https://huggingface.co/THUDM/codegeex2-6b) |
| MiniCPM | [link](https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16) |

Resources from: https://github.com/intel-analytics/ipex-llm/

## Contribution
We welcome contributions to the verified model list.

## Qwen2 Model (Experimental)
1. Upgrade `transformers`. `pip install --upgrade transformers~=4.42.3`.
2. Edit `lib\site-packages\transformers\models\qwen2\modeling_qwen2.py`.
3. Change `from transformers.models.qwen2.modeling_qwen2 import _prepare_4d_causal_attention_mask` to
`from transformers.modeling_attn_mask_utils import _prepare_4d_causal_attention_mask`.

### FAQ
```
ImportError: cannot import name '_prepare_4d_causal_attention_mask' from 'transformers.models.qwen2.modeling_qwen2' (C:\Users\hpintel\anaconda3\envs\ellmipex\lib\site-packages\transformers\models\qwen2\modeling_qwen2.py)
```